{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## How to maximize GPU utilization by finding the right batch size"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install torch-tb-profiler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup\n",
    "\n",
    "Here we import the necessary package, instantiate our data and transformations, and set various variables we will use during this demo. We then define our training function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import all the necessary libraries \n",
    "import torch  \n",
    "import torch.nn  \n",
    "import torch.optim  \n",
    "import torch.profiler  \n",
    "import torch.utils.data  \n",
    "import torchvision.datasets  \n",
    "import torchvision.models  \n",
    "import torchvision.transforms as T    \n",
    "#prepare input data and transform it \n",
    "transform = T.Compose(  \n",
    "    [T.Resize(224),  \n",
    "     T.ToTensor(),  \n",
    "     T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  \n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)  \n",
    "# use dataloader to launch each batch \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=True, num_workers=4)  \n",
    "# Create a Resnet model, loss function, and optimizer objects. To run on GPU, move model and loss to a GPU device \n",
    "device = torch.device(\"cuda:0\")  \n",
    "model = torchvision.models.resnet18(pretrained=True).cuda(device) \n",
    "criterion = torch.nn.CrossEntropyLoss().cuda(device)  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  \n",
    "model.train()    \n",
    "# define the training step for each batch of input data \n",
    "def train(data):  \n",
    "    inputs, labels = data[0].to(device=device), data[1].to(device=device)  \n",
    "    outputs = model(inputs)  \n",
    "    loss = criterion(outputs, labels)  \n",
    "    optimizer.zero_grad()  \n",
    "    loss.backward()  \n",
    "    optimizer.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sample training loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with torch.profiler.profile(\n",
    "        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/resnet18_batchsize1'),  \n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    for step, batch_data in enumerate(train_loader):\n",
    "        if step >= (1 + 1 + 3) * 2:\n",
    "            break\n",
    "        train(batch_data)\n",
    "        prof.step()  # Need call this at the end of each step to notify profiler of steps' boundary."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(units=2, activation='sigmoid')\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(\n",
    "    x=scaled_train_samples,\n",
    "    y=train_labels,\n",
    "    validation_data=valid_set,\n",
    "    batch_size=10,\n",
    "    epochs=20,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}